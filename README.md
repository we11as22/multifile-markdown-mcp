# Agent Memory MCP Server

Multi-file markdown MCP server with hybrid search (vector + fulltext + RRF) for agent memory management. Can be used as MCP server or Python library.

## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

**9 —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤** - –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Å –º–∞—Å—Å–∏–≤–∞–º–∏, –±–µ–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è:
- üìÅ **files** - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞–º–∏ (create, read, update, delete, move, copy, rename, list)
- üîç **search** - –ü–æ–∏—Å–∫ —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º (vector + fulltext + RRF)
- ‚úèÔ∏è **edit** - –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–µ–∫—Ü–∏–∏, –ø–æ–∏—Å–∫/–∑–∞–º–µ–Ω–∞, –≤—Å—Ç–∞–≤–∫–∞)
- üè∑Ô∏è **tags** - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–≥–∞–º–∏ (add, remove, get)
- üéØ **main** - –û–ø–µ—Ä–∞—Ü–∏–∏ —Å main.md (append, goal, task, plan)
- üîß **memory** - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é (initialize, reset)
- üìÑ **extract** - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–∫—Ü–∏–π –∏–∑ —Ñ–∞–π–ª–æ–≤
- üìã **list** - –°–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏ —Å–µ–∫—Ü–∏–π
- üí° **help** - –ü–æ–º–æ—â—å, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –≥–∞–π–¥—ã –∏ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

**–í—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞—é—Ç —Å –º–∞—Å—Å–∏–≤–∞–º–∏** - –Ω–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ batch –∏ –Ω–µ-batch –≤–µ—Ä—Å–∏–∏!

## Features

- **Persistent Memory**: Store agent memories in human-readable markdown files
- **Hybrid Search**: Combines vector (semantic) and fulltext (keyword) search with RRF ranking
- **Multiple Embedding Providers**: OpenAI, Cohere, Ollama, HuggingFace, LiteLLM
- **Intelligent Chunking**: Markdown-aware chunking with header context preservation
- **Automatic Sync**: File changes automatically sync to PostgreSQL + pgvector
- **MCP Integration**: Full MCP support via FastMCP (tools, resources, prompts)
- **Python Library**: Use as standalone Python library with LangChain integration
- **Batch Operations**: Efficient batch create/update/delete/search operations
- **JSON Index**: Complete file metadata in `files_index.json` for fast access
- **Memory Management**: Initialize and reset memory to base state
- **Structured Memory**: Organized by categories (projects, concepts, conversations, preferences)
- **Goal & Task Tracking**: Built-in support for current goals and completed tasks

## Architecture

```
MCP Client (Claude) ‚Üî FastMCP Server ‚Üî Memory Manager
                                           ‚îú‚îÄ File Manager (Markdown CRUD)
                                           ‚îú‚îÄ Search Engine (Hybrid RRF)
                                           ‚îú‚îÄ JSON Index Manager
                                           ‚îî‚îÄ Sync Service (File ‚Üî DB)
                                               ‚Üì
                                        PostgreSQL + pgvector
```

## Installation

### As Python Library (Recommended)

Install via pip:

```bash
pip install agent-memory-mcp
```

Or install from source:

```bash
git clone https://github.com/we11as22/multifile-markdown-mcp.git
cd multifile-markdown-mcp
pip install -e .
```

### As MCP Server (Docker)

#### –° –ë–î (–ø–æ–ª–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª —Å –ø–æ–∏—Å–∫–æ–º)

1. Clone the repository:
```bash
git clone https://github.com/we11as22/multifile-markdown-mcp.git
cd multifile-markdown-mcp
```

2. Copy environment template:
```bash
cp .env.example .env
```

3. Edit `.env` and configure your embedding provider:
```bash
# For OpenAI
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here

# OR for Ollama (local, free)
EMBEDDING_PROVIDER=ollama
OLLAMA_BASE_URL=http://ollama:11434
```

4. Start services:
```bash
cd docker
docker-compose up -d
```

5. Check logs:
```bash
docker-compose logs -f mcp-server
```

#### –ë–µ–∑ –ë–î (file-only mode)

–î–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ –ë–î (–±–µ–∑ –ø–æ–∏—Å–∫–∞, –Ω–æ —Å–æ –≤—Å–µ–º–∏ –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏):

**–í–∞—Ä–∏–∞–Ω—Ç 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π compose —Ñ–∞–π–ª (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)**
```bash
cd docker
docker-compose -f docker-compose.file-only.yml up -d
```

**–í–∞—Ä–∏–∞–Ω—Ç 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π compose —Å –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è**
```bash
cd docker

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
export USE_DATABASE=false

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–æ–ª—å–∫–æ MCP —Å–µ—Ä–≤–µ—Ä (–±–µ–∑ postgres –∏ ollama)
docker-compose up -d mcp-server
```

**–í–∞—Ä–∏–∞–Ω—Ç 3: –ß–µ—Ä–µ–∑ .env —Ñ–∞–π–ª**
```bash
cd docker

# –°–æ–∑–¥–∞—Ç—å/–æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å .env
echo "USE_DATABASE=false" >> .env

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–æ–ª—å–∫–æ MCP —Å–µ—Ä–≤–µ—Ä
docker-compose up -d mcp-server
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏
docker-compose logs -f mcp-server

# –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ: "database_disabled_using_file_only_mode"
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Ä–µ–∂–∏–º–∞ –±–µ–∑ –ë–î:**
- ‚úÖ –ù–µ —Ç—Ä–µ–±—É–µ—Ç PostgreSQL
- ‚úÖ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–Ω–µ –Ω—É–∂–Ω–æ –∂–¥–∞—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î)
- ‚úÖ –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ñ–∞–π–ª–∞–º–∏ —Ä–∞–±–æ—Ç–∞—é—Ç
- ‚úÖ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–≥–∞–º–∏ —á–µ—Ä–µ–∑ JSON index
- ‚úÖ –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —Å –¥–µ—Ä–µ–≤–æ–º –∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
- ‚úÖ –û–ø–µ—Ä–∞—Ü–∏–∏ —Å main.md —Ä–∞–±–æ—Ç–∞—é—Ç
- ‚ùå –ü–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Ç—Ä–µ–±—É–µ—Ç –ë–î)

## Usage

### As Python Library

```python
import asyncio
from agent_memory_mcp import MemoryLibrary

async def main():
    # Initialize library
    memory = MemoryLibrary(
        memory_files_path="./memory",
        database_url="postgresql+asyncpg://user:pass@localhost/agent_memory"
    )
    await memory.initialize()

    # Create a memory file
    result = await memory.create_file(
        title="My Project",
        category="project",
        content="# My Project\n\nProject description...",
        tags=["important", "active"]
    )

    # Search memories
    results = await memory.search(
        query="project details",
        search_mode="hybrid",
        limit=10
    )

    # Batch operations
    files = [
        {"title": "File 1", "category": "project", "content": "# File 1"},
        {"title": "File 2", "category": "concept", "content": "# File 2"},
    ]
    await memory.batch_create_files(files)

    # Cleanup
    await memory.close()

asyncio.run(main())
```

### LangChain Integration

```python
from agent_memory_mcp import MemoryLibrary, get_langchain_tools
from langchain.agents import Agent

# Initialize memory
memory = MemoryLibrary(...)
await memory.initialize()

# Get LangChain tools
tools = get_langchain_tools(memory)

# Use in agent
agent = Agent(tools=tools)
```

### Memory Initialization and Reset

```python
# Initialize memory to base state (creates main.md and files_index.json)
await memory.initialize_memory()

# Reset memory (deletes all files except main.md and files_index.json)
await memory.reset_memory()
```

## Configuration

### File-Only Mode (–ë–µ–∑ –ë–î)

–°–µ—Ä–≤–∏—Å –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å **–±–µ–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö** –≤ —Ä–µ–∂–∏–º–µ —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤. –í —ç—Ç–æ–º —Ä–µ–∂–∏–º–µ:
- ‚úÖ –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å —Ñ–∞–π–ª–∞–º–∏ —Ä–∞–±–æ—Ç–∞—é—Ç (create, read, update, delete, move, copy, rename)
- ‚úÖ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–≥–∞–º–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ JSON index
- ‚úÖ –û–ø–µ—Ä–∞—Ü–∏–∏ —Å main.md —Ä–∞–±–æ—Ç–∞—é—Ç
- ‚úÖ –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ä–µ–≤–æ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
- ‚ùå –ü–æ–∏—Å–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Ç—Ä–µ–±—É–µ—Ç –ë–î)

**–í–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –±–µ–∑ –ë–î:**

–ß–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è:
```bash
export USE_DATABASE=false
```

–ò–ª–∏ –≤ –∫–æ–¥–µ:
```python
memory = MemoryLibrary(
    memory_files_path="./memory",
    use_database=False  # –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –±–µ–∑ –ë–î
)
await memory.initialize()
```

**–°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —Å –¥–µ—Ä–µ–≤–æ–º:**
```python
result = await memory.list_files()
# result —Å–æ–¥–µ—Ä–∂–∏—Ç:
# {
#   "files": [...],  # –ü–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
#   "tree": {         # –î–µ—Ä–µ–≤–æ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
#     "projects": [
#       {
#         "file_path": "projects/project_1.md",
#         "title": "Project 1",
#         "description": "–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞",
#         "tags": ["important"],
#         "updated_at": "2025-12-29T...",
#         "word_count": 150
#       }
#     ],
#     "concepts": [...]
#   },
#   "total": 10
# }
```

### Environment Variables

Set `MEMORY_FILES_PATH` to specify memory directory:

```bash
export MEMORY_FILES_PATH=/path/to/memory
```

Or use in code:

```python
memory = MemoryLibrary(
    memory_files_path="/path/to/memory",
    database_url="..."  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ use_database=True
)
```

### Embedding Providers

#### OpenAI (Recommended)
```bash
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-...
OPENAI_EMBEDDING_MODEL=text-embedding-3-small  # or text-embedding-3-large
EMBEDDING_DIMENSION=1536  # 3072 for large
```

#### Ollama (Free, Local)
```bash
EMBEDDING_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
```

First, pull the model:
```bash
ollama pull nomic-embed-text
```

#### Cohere
```bash
EMBEDDING_PROVIDER=cohere
COHERE_API_KEY=your-key
COHERE_EMBEDDING_MODEL=embed-english-v3.0
```

#### HuggingFace (API or Local)
```bash
EMBEDDING_PROVIDER=huggingface
HUGGINGFACE_MODEL=sentence-transformers/all-MiniLM-L6-v2
HUGGINGFACE_USE_LOCAL=true  # Use local model
HUGGINGFACE_DEVICE=cpu  # or cuda
```

#### LiteLLM (Universal Proxy)
```bash
EMBEDDING_PROVIDER=litellm
LITELLM_MODEL=text-embedding-3-small
# Set provider-specific API keys as needed
```

### Search Configuration

```bash
CHUNK_SIZE=800              # Max chunk size in characters
CHUNK_OVERLAP=200           # Overlap between chunks
SEARCH_LIMIT=20             # Default result limit
RRF_K=60                    # RRF k parameter (higher = less ranking difference)
```

## MCP Tools

–°–µ—Ä–≤–∏—Å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç **9 —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤**. –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Å –º–∞—Å—Å–∏–≤–∞–º–∏ - –Ω–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ–∂–¥—É batch –∏ –Ω–µ-batch –≤–µ—Ä—Å–∏—è–º–∏.

### üìÅ 1. files - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞–º–∏

**–í—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–∞—Å—Å–∏–≤–æ–º –æ–ø–µ—Ä–∞—Ü–∏–π.** –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏: `create`, `read`, `update`, `delete`, `move`, `copy`, `rename`, `list`.

```python
# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
files(operation="create", items=[
    {"title": "Project 1", "category": "project", "content": "# Project 1", "tags": ["important"]},
    {"title": "Concept 1", "category": "concept", "content": "# Concept 1"},
])

# –ß—Ç–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
files(operation="read", items=[
    {"file_path": "projects/project_1.md"},
    {"file_path": "concepts/concept_1.md"},
])

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
files(operation="update", items=[
    {"file_path": "projects/project_1.md", "content": "# Updated", "update_mode": "replace"},
    {"file_path": "concepts/concept_1.md", "content": "# More content", "update_mode": "append"},
])

# –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
files(operation="delete", items=[
    {"file_path": "projects/old_project.md"},
])

# –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
files(operation="move", items=[
    {"file_path": "projects/project.md", "new_category": "concept"},
])

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
files(operation="copy", items=[
    {"source_file_path": "projects/original.md", "new_title": "Copy", "new_category": "concept"},
])

# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
files(operation="rename", items=[
    {"old_file_path": "projects/old_name.md", "new_title": "New Name"},
])

# –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
files(operation="list", items=[
    {"category": "project"},  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
])
```

### üîç 2. search - –ü–æ–∏—Å–∫

**–í—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–∞—Å—Å–∏–≤–æ–º –∑–∞–ø—Ä–æ—Å–æ–≤.** –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–µ–∂–∏–º—ã: `hybrid` (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è), `vector`, `fulltext`.

```python
# –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
search(queries=[
    {
        "query": "machine learning",
        "search_mode": "hybrid",
        "limit": 10,
        "category_filter": "concept",  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        "tag_filter": ["important"],  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
    },
    {
        "query": "neural networks",
        "file_path": "concepts/ml.md",  # –ø–æ–∏—Å–∫ –≤–Ω—É—Ç—Ä–∏ —Ñ–∞–π–ª–∞
        "limit": 5,
    },
])
```

**–†–µ–∂–∏–º—ã –ø–æ–∏—Å–∫–∞:**
- `hybrid` (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è): –ö–æ–º–±–∏–Ω–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏ –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º RRF
- `vector`: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º embeddings
- `fulltext`: –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PostgreSQL fulltext

### ‚úèÔ∏è 3. edit - –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

**–í—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–∞—Å—Å–∏–≤–æ–º –æ–ø–µ—Ä–∞—Ü–∏–π.** –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–∏–ø—ã: `section`, `find_replace`, `insert`.

```python
# –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
edit(operations=[
    {
        "file_path": "projects/project.md",
        "edit_type": "section",
        "section_header": "## Status",
        "new_content": "In progress",
        "mode": "replace"  # replace, append, prepend
    },
    {
        "file_path": "notes.md",
        "edit_type": "find_replace",
        "find": "old text",
        "replace": "new text",
        "regex": false,  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        "max_replacements": -1  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, -1 –¥–ª—è –≤—Å–µ—Ö
    },
    {
        "file_path": "notes.md",
        "edit_type": "insert",
        "content": "New note",
        "position": "end",  # start, end, after_marker
        "marker": "<!-- insert here -->"  # –¥–ª—è after_marker
    },
])
```

### üè∑Ô∏è 4. tags - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–≥–∞–º–∏

**–í—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–∞—Å—Å–∏–≤–æ–º —Ñ–∞–π–ª–æ–≤.** –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏: `add`, `remove`, `get`.

```python
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ –∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Ñ–∞–π–ª–∞–º
tags(operation="add", items=[
    {"file_path": "projects/project1.md", "tags": ["important", "active"]},
    {"file_path": "projects/project2.md", "tags": ["important"]},
])

# –£–¥–∞–ª–µ–Ω–∏–µ —Ç–µ–≥–æ–≤
tags(operation="remove", items=[
    {"file_path": "projects/project1.md", "tags": ["old-tag"]},
])

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–≥–æ–≤
tags(operation="get", items=[
    {"file_path": "projects/project1.md"},
])
```

### üéØ 5. main - –û–ø–µ—Ä–∞—Ü–∏–∏ —Å main.md

**–í—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–∞—Å—Å–∏–≤–æ–º –æ–ø–µ—Ä–∞—Ü–∏–π.** –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏: `append`, `goal`, `task`, `plan`.

```python
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–º–µ—Ç–æ–∫ –≤ —Å–µ–∫—Ü–∏–∏
main(operation="append", items=[
    {"content": "Important note", "section": "Recent Notes"},  # Recent Notes, Current Goals, Future Plans, Plans, Quick Reference
])

# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ü–µ–ª—è–º–∏
main(operation="goal", items=[
    {"goal": "Complete project", "action": "add"},  # add, complete, remove
    {"goal": "Test system", "action": "add"},
])

# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏
main(operation="task", items=[
    {"task": "Completed task 1", "action": "add"},
])

# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–ª–∞–Ω–∞–º–∏
main(operation="plan", items=[
    {"plan": "Implement feature X", "action": "add"},  # add, complete
])
```

### üîß 6. memory - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏: `initialize`, `reset`.

```python
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
memory(operation="initialize")

# –°–±—Ä–æ—Å –ø–∞–º—è—Ç–∏
memory(operation="reset")
```

### üìÑ 7. extract - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–∫—Ü–∏–π

**–í—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–∞—Å—Å–∏–≤–æ–º –∑–∞–ø—Ä–æ—Å–æ–≤.**

```python
# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–∫—Ü–∏–π –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
extract(requests=[
    {"file_path": "projects/project.md", "section_header": "## Status"},
    {"file_path": "concepts/concept.md", "section_header": "## Details"},
])
```

### üìã 8. list - –°–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏ —Å–µ–∫—Ü–∏–π

**–í—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –º–∞—Å—Å–∏–≤–æ–º –∑–∞–ø—Ä–æ—Å–æ–≤.** –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–∏–ø—ã: `files`, `sections`.

**–°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ä–µ–≤–æ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏:**
```python
list(requests=[{"type": "files", "category": "project"}])
# –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
# {
#   "results": [{
#     "files": [...],  # –ü–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
#     "tree": {        # –î–µ—Ä–µ–≤–æ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
#       "projects": [
#         {
#           "file_path": "projects/project_1.md",
#           "title": "Project 1",
#           "description": "–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞",
#           "tags": ["important"],
#           "updated_at": "2025-12-29T...",
#           "word_count": 150
#         }
#       ]
#     },
#     "total": 5
#   }]
# }
```

```python
# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–æ–≤ —Ñ–∞–π–ª–æ–≤ –∏ —Å–µ–∫—Ü–∏–π
list(requests=[
    {"type": "files", "category": "project"},  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
    {"type": "sections", "file_path": "projects/project.md"},
])
```

### üí° 9. help - –ü–æ–º–æ—â—å –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

**–ï–¥–∏–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–º–æ—â–∏, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, –≥–∞–π–¥–æ–≤ –∏ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.**

```python
# –ü–æ–ª–Ω—ã–π –≥–∞–π–¥
help(topic=None)  # –∏–ª–∏ help(topic="all")

# –ì–∞–π–¥ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–µ–º–µ
help(topic="files")  # files, search, edit, tags, main, memory, extract, list, examples
```

## MCP Resources

–ü—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ —Ñ–∞–π–ª–∞–º –ø–∞–º—è—Ç–∏ —á–µ—Ä–µ–∑ —Ä–µ—Å—É—Ä—Å—ã:

- **`memory://main`** - –ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª –∑–∞–º–µ—Ç–æ–∫ –∞–≥–µ–Ω—Ç–∞ (main.md)
- **`memory://file/{file_path}`** - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª –ø–∞–º—è—Ç–∏ –ø–æ –ø—É—Ç–∏

**–ü—Ä–∏–º–µ—Ä—ã:**
- `memory://main` - –ø–æ–ª—É—á–∏—Ç—å main.md
- `memory://file/projects/my_project.md` - –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–æ–µ–∫—Ç–∞

## MCP Prompts

–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏:

### `remember_conversation(topic, key_points)`
–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–∞–º—è—Ç—å –æ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
```python
{
  "topic": "–û–±—Å—É–∂–¥–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞",
  "key_points": "–û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã —Ä–∞–∑–≥–æ–≤–æ—Ä–∞..."
}
```
–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ `conversation` —Å –¥–∞—Ç–æ–π, –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º, –∫–ª—é—á–µ–≤—ã–º–∏ –º–æ–º–µ–Ω—Ç–∞–º–∏, —Ä–µ—à–µ–Ω–∏—è–º–∏ –∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏.

### `recall_context(topic)`
–ü–æ–∏—Å–∫ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å —Å–æ–≤–µ—Ç–∞–º–∏ –ø–æ –ø–æ–∏—Å–∫—É.
```python
{
  "topic": "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ"
}
```
–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–º–µ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

### `memory_usage_guide()`
–ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏.
–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—Å–µ—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫.

### `active_memory_usage()`
–ü—Ä–æ–º–ø—Ç, –ø–æ–æ—â—Ä—è—é—â–∏–π –∞–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏.
–ù–∞–ø–æ–º–∏–Ω–∞–µ—Ç –∞–≥–µ–Ω—Ç—É –æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –ø–∞–º—è—Ç–∏ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –≤—Å–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.

**–í–∞–∂–Ω–æ:** –ê–≥–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –∞–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –ø–∞–º—è—Ç–∏ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –≤—Å–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ª—É—á—à–µ–π –ø–æ–º–æ—â–∏.

## –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

### –í—Å–µ–≥–æ –¥–æ—Å—Ç—É–ø–Ω–æ 9 —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤:

1. **`files`** - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞–º–∏ (create, read, update, delete, move, copy, rename, list)
2. **`search`** - –ü–æ–∏—Å–∫ (hybrid, vector, fulltext)
3. **`edit`** - –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (section, find_replace, insert)
4. **`tags`** - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–≥–∞–º–∏ (add, remove, get)
5. **`main`** - –û–ø–µ—Ä–∞—Ü–∏–∏ —Å main.md (append, goal, task, plan)
6. **`memory`** - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é (initialize, reset)
7. **`extract`** - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–∫—Ü–∏–π
8. **`list`** - –°–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏ —Å–µ–∫—Ü–∏–π
9. **`help`** - –ü–æ–º–æ—â—å, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –≥–∞–π–¥—ã –∏ –ø—Ä–∏–º–µ—Ä—ã

**–í—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞—é—Ç —Å –º–∞—Å—Å–∏–≤–∞–º–∏** - –Ω–µ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ batch –∏ –Ω–µ-batch –≤–µ—Ä—Å–∏–∏!

**–†–µ—Å—É—Ä—Å—ã (2):**
- `memory://main` - –ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª
- `memory://file/{path}` - –§–∞–π–ª –ø–æ –ø—É—Ç–∏

**–ü—Ä–æ–º–ø—Ç—ã (4):**
- `remember_conversation` - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä
- `recall_context` - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç
- `memory_usage_guide` - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ
- `active_memory_usage` - –ê–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

## Memory Structure

```
memory_files/
‚îú‚îÄ‚îÄ main.md                    # Central hub with index and goals
‚îú‚îÄ‚îÄ files_index.json          # JSON index with complete file metadata
‚îú‚îÄ‚îÄ projects/
‚îÇ   ‚îú‚îÄ‚îÄ project_alpha.md
‚îÇ   ‚îî‚îÄ‚îÄ project_beta.md
‚îú‚îÄ‚îÄ concepts/
‚îÇ   ‚îú‚îÄ‚îÄ technical_concepts.md
‚îÇ   ‚îî‚îÄ‚îÄ domain_knowledge.md
‚îú‚îÄ‚îÄ conversations/
‚îÇ   ‚îî‚îÄ‚îÄ conversation_2025_01.md
‚îî‚îÄ‚îÄ preferences/
    ‚îî‚îÄ‚îÄ user_preferences.md
```

### Base State

The base state consists of:
- `main.md` - Main memory file with index and goals
- `files_index.json` - JSON file with complete metadata for all files

Use `initialize_memory()` to create base state and `reset_memory()` to restore it.

### main.md Structure

```markdown
# Agent Memory - Main Notes

Last Updated: 2025-01-15

## File Index

This section maintains an index of all specialized memory files with descriptions.

### Projects
- [Project Alpha](/memory_files/projects/project_alpha.md) - Description

### Concepts
- [Technical Concepts](/memory_files/concepts/technical_concepts.md) - Description

## Current Goals
- [ ] Goal 1
- [ ] Goal 2

## Completed Tasks
- [x] Task 1 (completed 2025-01-15)

## Future Plans
- Plan 1

## Recent Notes
### 2025-01-15 - Session Notes
- Note 1

## Quick Reference
- Key info
```

### files_index.json Structure

```json
{
  "version": "1.0",
  "last_updated": "2025-01-15T10:00:00Z",
  "files": [
    {
      "file_path": "projects/project_alpha.md",
      "title": "Project Alpha",
      "category": "project",
      "description": "Main project description",
      "tags": ["important", "active"],
      "metadata": {},
      "created_at": "2025-01-10T10:00:00Z",
      "updated_at": "2025-01-15T10:00:00Z",
      "word_count": 1500
    }
  ]
}
```

## Database Schema

### Tables

**memory_files** - File metadata
- id, file_path, title, category
- created_at, updated_at, file_hash
- word_count, tags (array), metadata (JSONB)

**memory_chunks** - Text chunks with embeddings
- id, file_id, chunk_index, content
- embedding (vector), header_path, section_level
- content_tsvector (fulltext index)

**sync_status** - Sync tracking
- file_id, last_synced_at, sync_status

### Hybrid Search Algorithm

Uses **Reciprocal Rank Fusion (RRF)**:

```
RRF_score = sum(1/(rank_vector + k)) + sum(1/(rank_fulltext + k))
```

Where:
- `rank_vector`: Position in semantic similarity results
- `rank_fulltext`: Position in keyword (BM25) results
- `k`: Constant (default 60) to reduce rank difference impact

## Testing

### Run Tests

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests (requires PostgreSQL)
pytest tests/ -v

# Run library tests specifically
pytest tests/test_library.py -v
```

### Manual Testing Script

```bash
# Start PostgreSQL
cd docker
docker-compose up -d postgres

# Set environment variables
export POSTGRES_HOST=localhost
export POSTGRES_PORT=5432
export POSTGRES_DB=agent_memory
export POSTGRES_USER=memory_user
export POSTGRES_PASSWORD=change_me_in_production

# Run manual test script
python scripts/test_library_manual.py
```

## Development

### Project Structure

```
src/
‚îú‚îÄ‚îÄ main.py                # FastMCP entry point
‚îú‚îÄ‚îÄ library.py             # Python library interface
‚îú‚îÄ‚îÄ models/                # Pydantic models
‚îú‚îÄ‚îÄ storage/               # File management + JSON index
‚îú‚îÄ‚îÄ database/              # PostgreSQL + SQLAlchemy
‚îú‚îÄ‚îÄ embeddings/            # Provider implementations
‚îú‚îÄ‚îÄ search/                # Chunking + hybrid search
‚îú‚îÄ‚îÄ sync/                  # File ‚Üî DB sync
‚îî‚îÄ‚îÄ mcp/                   # MCP tools/resources/prompts
```

### Running Locally (Development)

1. Install dependencies:
```bash
pip install -e ".[dev]"
```

2. Start PostgreSQL:
```bash
cd docker
docker-compose up -d postgres
```

3. Run MCP server:
```bash
python -m src.main
```

4. Or use as library:
```python
from agent_memory_mcp import MemoryLibrary

memory = MemoryLibrary(...)
await memory.initialize()
```

## Performance

- **Batch Embedding**: 100 chunks per batch
- **Connection Pool**: 5-20 connections
- **Vector Index**: IVFFlat (100 lists)
- **Fulltext Index**: GIN (tsvector)
- **Batch Operations**: Process multiple items efficiently

## Best Practices

1. **–í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Å –º–∞—Å—Å–∏–≤–∞–º–∏** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–∞—Å—Å–∏–≤—ã –¥–∞–∂–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
2. **Search before creating** - –∏—â–∏—Ç–µ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
3. **Use descriptive titles and tags** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Ç–µ–≥–∏
4. **Keep main.md updated** - –æ–±–Ω–æ–≤–ª—è–π—Ç–µ —Ü–µ–ª–∏, –∑–∞–¥–∞—á–∏ –∏ –ø–ª–∞–Ω—ã –≤ main.md
5. **Actively use memory** - –∞–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–∞–º—è—Ç—å –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
6. **Use hybrid search mode** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
7. **Initialize memory** - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –ø–µ—Ä–≤—ã–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
8. **Use help tool** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç help –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏ –ø—Ä–∏–º–µ—Ä–æ–≤

## Troubleshooting

### Database connection fails
```bash
# Check PostgreSQL is running
docker-compose ps postgres

# Check logs
docker-compose logs postgres

# Verify connection string
echo $DATABASE_URL
```

### Embedding provider errors

**OpenAI**: Verify API key and credits
**Ollama**: Ensure model is pulled (`ollama pull nomic-embed-text`)
**Cohere**: Check API key and quotas
**HuggingFace**: Verify API key or local model path

### Search returns no results

1. Check files are synced: `docker-compose logs mcp-server | grep sync`
2. Verify embeddings generated: Check `memory_chunks` table has `embedding` values
3. Try different search modes (vector, fulltext, hybrid)
4. Check database connection is active

### Library initialization fails

1. Verify database URL is correct
2. Check PostgreSQL is running and accessible
3. Ensure database exists and user has permissions
4. Check environment variables are set correctly

## License

MIT License

## Contributing

Contributions welcome! Please open an issue or PR.

## Support

For issues: https://github.com/we11as22/multifile-markdown-mcp/issues
